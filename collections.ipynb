{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python code that can get all the rarity ranks of the tokens in these collections. You can use Opensea API, RaritySniper API, Looksrare platform, or any other platform/ source/ API to get these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/Collections_Assignment.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load opensea API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('config/config.yaml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "API_KEY = config['API_KEY']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fetching collection stats using opensea API and collection slug - unique to a NFT Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests\n",
    "collection_slug = \"robofrens\"\n",
    "\n",
    "url = f\"https://api.opensea.io/api/v2/collections/{collection_slug}/stats\"\n",
    "\n",
    "headers = {\"accept\": \"application/json\", \"X-API-KEY\": API_KEY}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "resp = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['contract_address', 'collection_slug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_slugs = list(data['collection_slug'].drop_duplicates().to_numpy())\n",
    "len(collection_slugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.opensea.io/api/v2/traits/collection_slug\"\n",
    "\n",
    "headers = {\"accept\": \"application/json\"}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Collection Stats: 100%|██████████| 739/739 [28:34<00:00,  2.32s/it]    \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "collection_stats = []\n",
    "\n",
    "def fetch_collection_stats(cs):\n",
    "    url = f\"https://api.opensea.io/api/v2/collections/{cs}/stats\"\n",
    "    headers = {\"accept\": \"application/json\", \"X-API-KEY\": API_KEY}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return ast.literal_eval(response.text)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Use ThreadPoolExecutor to make parallel API calls\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:  # You can adjust max_workers as needed\n",
    "    futures = [executor.submit(fetch_collection_stats, cs) for cs in collection_slugs]\n",
    "\n",
    "    # tqdm to display progress bar\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Fetching Collection Stats\"):\n",
    "        result = future.result()\n",
    "        collection_stats.append(result)\n",
    "        time.sleep(1)  # Add a delay between requests to avoid rate limiting\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collection_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_stats_df = pd.DataFrame({'collection_slug': collection_slugs, 'collection_stats': collection_stats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(739, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_stats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(739, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_stats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_stats_df.to_pickle(\"data/collection_stats_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(863, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collection_stats = data.merge(collection_stats_df, on = 'collection_slug')\n",
    "data_collection_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection_stats.columns = ['contract_address', 'collection_slug', 'collection_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection_stats = data_collection_stats[['collection_slug', 'contract_address', 'collection_stats']]\n",
    "data_collection_stats.to_pickle(\"data/data_collection_stats.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below - details on nfts corresponding to a collection can be found, however max no of nfts that can be fetched from a collection is 200, so to fetch the next set of 200 nfts we use the next address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.opensea.io/api/v2/collection/robofrens/nfts?limit=200\"\n",
    "\n",
    "payload = {}\n",
    "headers = {\n",
    "  'accept': 'application/json',\n",
    "  'X-API-KEY': API_KEY,\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "resp = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resp['nfts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fetching the next 200 nfts using next cursor value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.opensea.io/api/v2/collection/robofrens/nfts?limit=200&next=LXBrPTMwNzE5NzIxMg==\"\n",
    "\n",
    "payload = {}\n",
    "headers = {\n",
    "  'accept': 'application/json',\n",
    "  'X-API-KEY': API_KEY\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "resp2 = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'robo fren #776'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp['nfts'][0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'robo fren #576'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp2['nfts'][0]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as there is no direct way to get the total no of nfts within a collection, without iterating through next parameter, until its complete,  using opensea, \n",
    "\n",
    "I will be using raritysniper that directly gives the totalsupply or nft count corresponding to a collection\n",
    "\n",
    "Here, the 'totalSupply' key for the API response - gives the total no of NFTs, and directly gives the associated rarity ranking based on the trait scores using its algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.raritysniper.com/public/collection/bearsontheblock\"\n",
    "\n",
    "payload = {}\n",
    "headers = {\n",
    "  'Referer': 'https://raritysniper.com/'\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "resp = response.json()\n",
    "\n",
    "collection_size = resp['totalSupply']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {}\n",
    "headers = {\n",
    "  'Referer': 'https://raritysniper.com/'\n",
    "}\n",
    "\n",
    "def size_of_collection(collection_slug):\n",
    "    url = f\"https://api.raritysniper.com/public/collection/{collection_slug}\"\n",
    "\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "    resp = response.json()\n",
    "    \n",
    "    try:\n",
    "\n",
    "        collection_size = resp['totalSupply']\n",
    "    except Exception:\n",
    "        collection_size = 0\n",
    "\n",
    "    return collection_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.raritysniper.com/public/collection/bearsontheblock/id/0\"\n",
    "\n",
    "payload = {}\n",
    "headers = {\n",
    "  'authority': 'api.raritysniper.com',\n",
    "  'accept': '*/*',\n",
    "  'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8',\n",
    "  'origin': 'https://raritysniper.com',\n",
    "  'referer': 'https://raritysniper.com/'\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "resp = response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on the totalSuppy aka total nft count - we can fetch nft wise ranks and traits - i.e ranging between 0 to totalSupply - 1,\n",
    "\n",
    "below returns trait values and rarity rank computer by rarity sniper's algorithm based on NFT's traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_slug = \"bearsontheblock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9495"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on robots.txt of raritysniper - we can infer that it allows crawling of all parts of the website\n",
    "\n",
    "User-agent: *\n",
    "\n",
    "Allow: /\n",
    "\n",
    "Sitemap: https://raritysniper.com/sitemap\n",
    "\n",
    "Sitemap: https://raritysniper.com/news/sitemap.xml\n",
    "\n",
    "Sitemap: https://raritysniper.com/news/sitemap-news.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfts_list = []\n",
    "nfts_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://api.raritysniper.com/public/collection/cryptopunks/id/0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_slug</th>\n",
       "      <th>contract_address</th>\n",
       "      <th>collection_stats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gotcha-gatcha</td>\n",
       "      <td>0x00dca92b7fbd0c01f3508756718807836ec82156</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rare-ghost-club</td>\n",
       "      <td>0x00fa82ea9be4e24ec6d7ed86ef93bfe85b9a3e68</td>\n",
       "      <td>{'total': {'volume': 0.18, 'sales': 2, 'averag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robofrens</td>\n",
       "      <td>0x01f61f3c7f27893b30e8abdafd4a84ca8bd24b96</td>\n",
       "      <td>{'total': {'volume': 848.3959432001659, 'sales...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bearsontheblock</td>\n",
       "      <td>0x02aa731631c6d7f8241d74f906f5b51724ab98f8</td>\n",
       "      <td>{'total': {'volume': 11.23, 'sales': 25, 'aver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>antvasion</td>\n",
       "      <td>0x03315ec191c834cbcf88068e24408033f0e3bf4a</td>\n",
       "      <td>{'total': {'volume': 26.24196, 'sales': 526, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   collection_slug                            contract_address  \\\n",
       "0    gotcha-gatcha  0x00dca92b7fbd0c01f3508756718807836ec82156   \n",
       "1  rare-ghost-club  0x00fa82ea9be4e24ec6d7ed86ef93bfe85b9a3e68   \n",
       "2        robofrens  0x01f61f3c7f27893b30e8abdafd4a84ca8bd24b96   \n",
       "3  bearsontheblock  0x02aa731631c6d7f8241d74f906f5b51724ab98f8   \n",
       "4        antvasion  0x03315ec191c834cbcf88068e24408033f0e3bf4a   \n",
       "\n",
       "                                    collection_stats  \n",
       "0                                               None  \n",
       "1  {'total': {'volume': 0.18, 'sales': 2, 'averag...  \n",
       "2  {'total': {'volume': 848.3959432001659, 'sales...  \n",
       "3  {'total': {'volume': 11.23, 'sales': 25, 'aver...  \n",
       "4  {'total': {'volume': 26.24196, 'sales': 526, '...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_pickle(\"data/data_collection_stats.pkl\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_slugs = list(data['collection_slug'].drop_duplicates().to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collection_slugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 739/739 [19:40<00:00,  1.60s/it]  \n"
     ]
    }
   ],
   "source": [
    "urls = []\n",
    "for collection_slug in tqdm(collection_slugs):\n",
    "    collection_size = size_of_collection(collection_slug)\n",
    "    logging.info(f\"collecting NFT traits for {collection_slug=},  {collection_size=}\")\n",
    "    \n",
    "    try:\n",
    "        for i in range(collection_size):\n",
    "            \n",
    "            url = f\"https://api.raritysniper.com/public/collection/{collection_slug}/id/{i}\"\n",
    "            urls.append((i, collection_slug, url))\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = pd.DataFrame(urls)\n",
    "url_df.to_pickle(\"data/url_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4152150, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129754.6875"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4152150/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 'gotcha-gatcha',\n",
       " 'https://api.raritysniper.com/public/collection/gotcha-gatcha/id/0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "url_df.to_pickle(\"data/url_df.pkl\")\n",
    "\n",
    "count = 0\n",
    "\n",
    "payload = {}\n",
    "headers = {\n",
    "        'authority': 'api.raritysniper.com',\n",
    "        'accept': 'application/json',\n",
    "        'origin': 'https://raritysniper.com'\n",
    "        }\n",
    "\n",
    "nfts_list = []\n",
    "\n",
    "async def fetch_data(session, url, collection_slug, i, progress_bar):\n",
    "    global count  # Add this line to declare count as a global variable\n",
    "    response = await session.get(url, headers=headers, data=payload)\n",
    "    resp = await response.json()\n",
    "    subset_dict = {key: resp[key] for key in ['rank', 'rarityScore', 'image', 'traits']}\n",
    "    subset_dict['collection_slug'] = collection_slug\n",
    "    subset_dict['nft_id'] = i\n",
    "    nfts_list.append(subset_dict)\n",
    "\n",
    "    global count  # Declare count as a global variable\n",
    "    count += 1\n",
    "    \n",
    "    progress_bar.update(1)  # Update the progress bar\n",
    "   \n",
    "    if count % 100 == 0:\n",
    "        nfts_df = pd.DataFrame(nfts_list)\n",
    "        nfts_df.to_pickle(\"data/nfts_df.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "max_concurrent_requests = 32\n",
    "\n",
    "\n",
    "\n",
    "async def bound_fetch(sem, func):\n",
    "    # Wrapper function to limit the number of concurrent calls\n",
    "    async with sem:\n",
    "        return await func\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # Limit the number of concurrent requests using asyncio.semaphore\n",
    "        with tqdm(total=len(urls)) as progress_bar:\n",
    "            tasks = [fetch_data(session, url, cs, i, progress_bar) for i, cs, url in urls]\n",
    "            semaphore = asyncio.Semaphore(max_concurrent_requests)\n",
    "            tasks = [bound_fetch(semaphore, fetch_data(session, url, collection_slug, i, progress_bar)) for i, collection_slug, url in urls]\n",
    "            results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "            print(f\"{len(results)=}\")\n",
    "            pd.DataFrame(results).to_pickle(\"data/results.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count() * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(863, 2)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collection_slugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
